{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inteligencia Artificial Explicable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/griverat/Meteo-AI/blob/main/notebooks/6.xAI.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si usa Google Colab, asegúrese de tener habilitada la GPU para este notebook.**\n",
    "\n",
    "![gpu_colab](https://github.com/griverat/Meteo-AI/blob/main/images/colab_gpu.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Descrición\n",
    "\n",
    "En este notebook se presenta un ejemplo de cómo se puede explicar un modelo de inteligencia artificial. Para ello, se utilizará un modelo simple y se explicará su comportamiento a través de multiples técnicas de explicabilidad.\n",
    "\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Entender cómo se puede explicar un modelo de inteligencia artificial.\n",
    "- Conocer las diferentes técnicas de explicabilidad.\n",
    "- Aplicar las técnicas de explicabilidad a un modelo simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install innvestigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"monospace\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inteliencia Artificial Explicable\n",
    "\n",
    "La inteligencia artificial explicable (XAI) es un campo de la inteligencia artificial (IA) que se preocupa por hacer que los sistemas de IA sean comprensibles para los seres humanos. La explicabilidad es importante porque los sistemas de IA pueden ser complejos y difíciles de entender, lo que puede hacer que sea difícil para los humanos confiar en ellos y tomar decisiones basadas en ellos.\n",
    "\n",
    "En el ámbito de ciencias del clima, la explicabilidad nos puede ayudar a entender cómo los modelos de IA toman decisiones y a interpretar sus resultados. Esto es importante porque nos puede ayudar a encontrar relaciones espacio-temporales en los datos y a entender cómo los modelos de IA pueden ser utilizados para predecir el clima.\n",
    "\n",
    "Para comenzar, necesitamos un modelo que podamos explicar. En este caso, utilizaremos primero un modelo pre-entrenado de clasificación de imágenes para obtener una idea general de como se usa xAI en la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo convolucional simple es suficiente para este propósito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=None),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenamos y visualizamos las métricas de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(history.history)\n",
    "history[[\"loss\", \"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnist_cnn.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de la explicabilidad\n",
    "\n",
    "Ahora vamos a explorar el uso de los métodos Integrated Gradients y LRP para explicar el modelo de clasificación de imágenes.\n",
    "\n",
    "El primer paso requerido por el paquete `innvestigate` es deshabilitar la ejecución de TensorFlow en modo eager. Esto quiere decir que las operaciones de TensorFlow se ejecutarán en modo gráfico, lo que permite a `innvestigate` analizar la estructura del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos tener en cuenta que `innvestigate` funciona solo cuando la ultima capa del modelo no tiene activación, debido a ello habiamos definido previamente la capa de salida como `None`.\n",
    "\n",
    "Ahora crearemos el analizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    model = tf.keras.models.load_model(\"mnist_cnn.keras\")\n",
    "    idx = np.random.randint(0, 10000, 10)\n",
    "    analyzer = innvestigate.create_analyzer(\"integrated_gradients\", model)\n",
    "    analysis = np.array(\n",
    "        [analyzer.analyze(_input.reshape(1, 28, 28, 1)) for _input in x_test[idx]]\n",
    "    ).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a analizar una imagen de ejemplo con el modelo y el analizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 2, figsize=(5, 20))\n",
    "for i, j in enumerate(idx):\n",
    "    axs[i, 0].imshow(x_test[j, :, :, 0], cmap=\"gray\")\n",
    "    axs[i, 0].axis(\"off\")\n",
    "    axs[i, 0].set_title(f\"True: {y_test[j]}\\nPred: {preds[j]}\")\n",
    "    axs[i, 1].imshow(analysis[i], cmap=\"seismic\", vmin=-0.01, vmax=0.01)\n",
    "    axs[i, 1].axis(\"off\")\n",
    "    axs[i, 1].set_title(\"Integrated Gradients\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a explorar con el LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    model = tf.keras.models.load_model(\"mnist_cnn.keras\")\n",
    "    analyzer_lrp = innvestigate.create_analyzer(\"lrp.sequential_preset_a\", model)\n",
    "    analysis_lrp = np.array(\n",
    "        [analyzer_lrp.analyze(_input.reshape(1, 28, 28, 1)) for _input in x_test[idx]]\n",
    "    ).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 2, figsize=(5, 20))\n",
    "for i, j in enumerate(idx):\n",
    "    axs[i, 0].imshow(x_test[j, :, :, 0], cmap=\"gray\")\n",
    "    axs[i, 0].axis(\"off\")\n",
    "    axs[i, 0].set_title(f\"True: {y_test[j]}\\nPred: {preds[j]}\")\n",
    "    axs[i, 1].imshow(analysis_lrp[i], cmap=\"seismic\", vmin=-0.0001, vmax=0.0001)\n",
    "    axs[i, 1].axis(\"off\")\n",
    "    axs[i, 1].set_title(\"LRP\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinando todo lado a lado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    model = tf.keras.models.load_model(\"mnist_cnn.keras\")\n",
    "    idx = np.random.randint(0, 10000, 10)\n",
    "    analyzer = innvestigate.create_analyzer(\"integrated_gradients\", model)\n",
    "    analysis = np.array(\n",
    "        [analyzer.analyze(_input.reshape(1, 28, 28, 1)) for _input in x_test[idx]]\n",
    "    ).squeeze()\n",
    "\n",
    "    analyzer_lrp = innvestigate.create_analyzer(\"lrp.sequential_preset_a\", model)\n",
    "    analysis_lrp = np.array(\n",
    "        [analyzer_lrp.analyze(_input.reshape(1, 28, 28, 1)) for _input in x_test[idx]]\n",
    "    ).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 3, figsize=(7.5, 20))\n",
    "for i, j in enumerate(idx):\n",
    "    axs[i, 0].imshow(x_test[j, :, :, 0], cmap=\"gray\")\n",
    "    axs[i, 0].axis(\"off\")\n",
    "    axs[i, 0].set_title(f\"True: {y_test[j]}\\nPred: {preds[j]}\")\n",
    "    axs[i, 1].imshow(analysis[i], cmap=\"seismic\", vmin=-0.01, vmax=0.01)\n",
    "    axs[i, 1].axis(\"off\")\n",
    "    axs[i, 1].set_title(\"Integrated Gradients\")\n",
    "    axs[i, 2].imshow(analysis_lrp[i], cmap=\"seismic\", vmin=-0.0001, vmax=0.0001)\n",
    "    axs[i, 2].axis(\"off\")\n",
    "    axs[i, 2].set_title(\"LRP\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
