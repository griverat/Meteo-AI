{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/griverat/Meteo-AI/blob/main/notebooks/4.rnn_datos.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si usa Google Colab, asegúrese de tener habilitada la GPU para este notebook.**\n",
    "\n",
    "![gpu_colab](../images/colab_gpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "\n",
    "Este notebook contiene el material a desarrollar durante la sesión de redes neuronales recurrentes. Se presentaran los conceptos básicos del uso de inteligencia artificial capaz de capturar tanto patrones espaciales como temporales en los datos.\n",
    "\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Entender el concepto de redes neuronales recurrentes\n",
    "- Comparar el rendimiento de una red neuronal recurrente\n",
    "- Implementar un modelo de pronóstico de series temporales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo correr esta celda si se usa google colab\n",
    "# Quitar el comentario (#) a los comandos que comienzan con !\n",
    "\n",
    "# !pip install ydata_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!wget https://raw.githubusercontent.com/griverat/Meteo-AI/main/notebooks/data/puerto_inca.csv -O data/puerto_inca.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes con características temporales\n",
    "\n",
    "Si bien las redes neuronales convolucionales (CNN) son muy buenas para capturar patrones espaciales, no son tan buenas para capturar patrones temporales en los datos. Para capturar patrones temporales, se pueden usar redes neuronales recurrentes (RNN) o redes neuronales convolucionales 1D (CNN1D). Para comenzar, se mostrará cómo usar redes neuronales recurrentes para predecir series temporales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import xarray as xr\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"monospace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(test_label, test_pred, xlim=(15, 45), ylim=(15, 45)):\n",
    "    coefs_keras = poly.polyfit(test_label.values.flatten(), test_pred, 1)\n",
    "    ffit_keras = poly.Polynomial(coefs_keras)\n",
    "    ffit_keras\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.scatter(test_label.values, test_pred, s=5)\n",
    "    ax.set_xlabel(\"True\")\n",
    "    ax.set_ylabel(\"Pred\")\n",
    "\n",
    "    x = np.linspace(15, 45, 100)\n",
    "    y = ffit_keras(x)\n",
    "    ax.plot(\n",
    "        x,\n",
    "        y,\n",
    "        color=\"red\",\n",
    "        lw=1,\n",
    "        label=f\"y = {coefs_keras[0]:.2f} + {coefs_keras[1]:.2f}x\",\n",
    "    )\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_title(\"True vs Pred\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "\n",
    "    # linea de 45 grados\n",
    "    ax.plot([15, 45], [15, 45], ls=\"--\", lw=0.5, color=\"black\")\n",
    "\n",
    "    ax.grid(ls=\"--\", lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "Las redes neuronales recurrentes (RNN) son un tipo de red neuronal que se especializa en capturar patrones temporales en los datos. A diferencia de las CNN, las RNN tienen conexiones recurrentes, lo que significa que la salida de una capa se alimenta de nuevo a la misma capa en el siguiente paso de tiempo. Esto permite que las RNN capturen patrones temporales en los datos.\n",
    "\n",
    "Para comenzar, vamos a cargar datos de la estacion Puerto Inca ubicada en la provincia de Huanuco, Perú."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.read_csv(\"data/puerto_inca.csv\", skiprows=10)\n",
    "\n",
    "# renombramos las columnas a algo más amigable\n",
    "station_data.columns = [\n",
    "    \"date\",\n",
    "    \"hour\",\n",
    "    \"temp\",\n",
    "    \"precip\",\n",
    "    \"humidity\",\n",
    "    \"wind_dir\",\n",
    "    \"wind_speed\",\n",
    "]\n",
    "\n",
    "# combinamos las columnas de fecha y hora en una sola\n",
    "station_data[\"date\"] = pd.to_datetime(station_data[\"date\"] + \" \" + station_data[\"hour\"])\n",
    "station_data = station_data.drop(columns=[\"hour\"])\n",
    "\n",
    "# para este ejemplo, solo nos interesa la fecha, temperatura y precipitación\n",
    "station_data = station_data[[\"date\", \"temp\", \"precip\"]]\n",
    "station_data[\"temp\"] = pd.to_numeric(\n",
    "    station_data[\"temp\"], errors=\"coerce\", downcast=\"float\"\n",
    ")\n",
    "station_data[\"precip\"] = pd.to_numeric(\n",
    "    station_data[\"precip\"], errors=\"coerce\", downcast=\"float\"\n",
    ")\n",
    "\n",
    "# eliminamos las filas con valores faltantes\n",
    "station_data = station_data.dropna()\n",
    "station_data = station_data.set_index(\"date\")\n",
    "station_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploramos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.describe(exclude=[np.datetime64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfileReport(station_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "station_data.plot(y=\"temp\", ax=ax[0])\n",
    "ax[0].set_title(\"Temperatura\")\n",
    "\n",
    "station_data.plot(y=\"precip\", ax=ax[1])\n",
    "ax[1].set_title(\"Precipitación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que los datos estan listo, usaremos Keras para crear nuestro modelo de RNN. Primero, guardamos una copia de nuestros datos originales para poder reutilizarlos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data_orig = station_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-One RNN\n",
    "\n",
    "En este caso, vamos a usar una red neuronal recurrente (RNN) para predecir la temperatura de la siguiente hora usando los datos de las ultimas 6h. Este es un ejemplo de una arquitectura de red neuronal recurrente de varios a uno.\n",
    "\n",
    "Preparamos los datos para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data[\"temp_1h\"] = station_data[\"temp\"].shift(1)\n",
    "station_data[\"temp_2h\"] = station_data[\"temp\"].shift(2)\n",
    "station_data[\"temp_3h\"] = station_data[\"temp\"].shift(3)\n",
    "station_data[\"temp_4h\"] = station_data[\"temp\"].shift(4)\n",
    "station_data[\"temp_5h\"] = station_data[\"temp\"].shift(5)\n",
    "\n",
    "station_data = station_data.dropna()\n",
    "\n",
    "station_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data[\"next_temp\"] = station_data[\"temp\"].shift(-1)\n",
    "\n",
    "# eliminamos la última fila, ya que no tiene un valor para la siguiente temperatura\n",
    "station_data = station_data.dropna()\n",
    "station_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(station_data) * 0.85)\n",
    "# el orden va desde la más antigua a la más reciente\n",
    "input_vars = [\"temp_5h\", \"temp_4h\", \"temp_3h\", \"temp_2h\", \"temp_1h\", \"temp\"]\n",
    "output_vars = [\"next_temp\"]\n",
    "train_data, test_data = (\n",
    "    station_data[input_vars].iloc[:train_size],\n",
    "    station_data[output_vars].iloc[train_size:],\n",
    ")\n",
    "\n",
    "train_label, test_label = (\n",
    "    station_data[input_vars].iloc[:train_size],\n",
    "    station_data[output_vars].iloc[train_size:],\n",
    ")\n",
    "\n",
    "# mean = train_data[\"temp\"].mean()\n",
    "# std = train_data[\"temp\"].std()\n",
    "\n",
    "# train_data = (train_data - mean) / std\n",
    "# test_data = (test_data - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definimos el modelo de RNN usando Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_to_one_rnn = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.SimpleRNN(8, input_shape=(6, 1), return_sequences=True),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "many_to_one_rnn.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "many_to_one_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, restore_best_weights=True, start_from_epoch=10\n",
    "    )\n",
    "]\n",
    "\n",
    "history = many_to_one_rnn.fit(\n",
    "    train_data.values.reshape(-1, 6, 1),\n",
    "    train_label.values,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = many_to_one_rnn.evaluate(test_data.values.reshape(-1, 1, 1), test_label.values)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axs[0].plot(history.history[\"loss\"], label=\"train\")\n",
    "axs[0].plot(history.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_title(\"Loss\")\n",
    "\n",
    "test_pred = many_to_one_rnn.predict(test_data.values.reshape(-1, 1)).flatten()\n",
    "axs[1].plot(test_label.values, label=\"test\")\n",
    "axs[1].plot(test_pred, label=\"test prediction\")\n",
    "axs[1].set_title(\"Prediction\")\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fit(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, tan solo definir un modelo simple de RNN con datos de entrada de 6 horas y una capa densa de salida nos da unos resultados bastante buenos. Pese a que no le hemos dado informacion al modelo de la estacionalidad de los datos, este ha sido capaz de capturar los patrones temporales en los datos y hacer una buena prediccion de la temperatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos probar con LSTM y GRU para ver si obtenemos mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_to_one_lstm = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.LSTM(8, input_shape=(6, 1), return_sequences=True),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "many_to_one_lstm.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "many_to_one_lstm.summary()\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, restore_best_weights=True, start_from_epoch=10\n",
    "    )\n",
    "]\n",
    "\n",
    "history = many_to_one_lstm.fit(\n",
    "    train_data.values.reshape(-1, 6, 1),\n",
    "    train_label.values,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = many_to_one_lstm.evaluate(test_data.values.reshape(-1, 1, 1), test_label.values)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axs[0].plot(history.history[\"loss\"], label=\"train\")\n",
    "axs[0].plot(history.history[\"val_loss\"], label=\"validation\")\n",
    "axs[0].set_title(\"Loss\")\n",
    "\n",
    "test_pred = many_to_one_lstm.predict(test_data.values.reshape(-1, 1)).flatten()\n",
    "axs[1].plot(test_label.values, label=\"test\")\n",
    "axs[1].plot(test_pred, label=\"test prediction\")\n",
    "axs[1].set_title(\"Prediction\")\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fit(test_label, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejericio\n",
    "La capa Gate Recurrent Unit (GRU) es una variante de la capa LSTM que es más simple y más rápida de entrenar. La GRU tiene menos parámetros que la LSTM y, en general, se comporta de manera similar. En este ejercicio, vamos a probar con una red GRU y comparar los resultados con los obtenidos con la red LSTM y RNN.\n",
    "\n",
    "Para usar la capa GRU en Keras, simplemente reemplace `LSTM` por `GRU` en la definición de la capa recurrente.\n",
    "\n",
    "```python\n",
    "model.add(tf.keras.layers.GRU(units=8, input_shape=(6, 1)))\n",
    "```\n",
    "\n",
    "1. Prueba con una red GRU y compara los resultados con los obtenidos con la red LSTM y RNN.\n",
    "\n",
    "2. Intente cambiar la cantidad de unidades en la capa recurrente y vea cómo afecta el rendimiento del modelo.\n",
    "\n",
    "3. Hemos estado usando `return_sequences=True` en la capa recurrente. ¿Qué sucede si cambiamos esto a `False`? ¿A qué se debe el cambio en el rendimiento del modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-Many RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a probar una arquitectura de red neuronal recurrente de varios a varios. En este caso, vamos a usar una red neuronal recurrente (RNN) para predecir la temperatura de las siguientes 6 horas usando los datos de las ultimas 6h.\n",
    "\n",
    "Vamos a hacer que la red neuronal pronostique los siguientes 6 datos de temperatura al mismo tiempo.\n",
    "\n",
    "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_lstm.png?raw=1\"></img>\n",
    "\n",
    "Preparamos los datos para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data_many = station_data.copy(deep=True)\n",
    "station_data_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data_many[\"next_temp_2h\"] = station_data_many[\"temp\"].shift(-2)\n",
    "station_data_many[\"next_temp_3h\"] = station_data_many[\"temp\"].shift(-3)\n",
    "station_data_many[\"next_temp_4h\"] = station_data_many[\"temp\"].shift(-4)\n",
    "station_data_many[\"next_temp_5h\"] = station_data_many[\"temp\"].shift(-5)\n",
    "station_data_many[\"next_temp_6h\"] = station_data_many[\"temp\"].shift(-6)\n",
    "\n",
    "station_data_many = station_data_many.dropna()\n",
    "station_data_many.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(station_data_many) * 0.85)\n",
    "# el orden va desde la más antigua a la más reciente\n",
    "input_vars = [\"temp_5h\", \"temp_4h\", \"temp_3h\", \"temp_2h\", \"temp_1h\", \"temp\"]\n",
    "output_vars = [\n",
    "    \"next_temp\",\n",
    "    \"next_temp_2h\",\n",
    "    \"next_temp_3h\",\n",
    "    \"next_temp_4h\",\n",
    "    \"next_temp_5h\",\n",
    "    \"next_temp_6h\",\n",
    "]\n",
    "train_data, test_data = (\n",
    "    station_data_many[input_vars].iloc[:train_size],\n",
    "    station_data_many[output_vars].iloc[train_size:],\n",
    ")\n",
    "\n",
    "train_label, test_label = (\n",
    "    station_data_many[input_vars].iloc[:train_size],\n",
    "    station_data_many[output_vars].iloc[train_size:],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definimos el modelo usando Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_to_many = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.LSTM(8, input_shape=(6, 1)),\n",
    "        tf.keras.layers.Dense(6),\n",
    "    ]\n",
    ")\n",
    "\n",
    "many_to_many.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "many_to_many.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, restore_best_weights=True, start_from_epoch=10\n",
    "    )\n",
    "]\n",
    "\n",
    "history = many_to_many.fit(\n",
    "    train_data.values.reshape(-1, 6, 1),\n",
    "    train_label.values.reshape(-1, 6, 1),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = many_to_many.evaluate(\n",
    "    test_data.values.reshape(-1, 6, 1), test_label.values.reshape(-1, 6, 1)\n",
    ")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.plot(history.history[\"loss\"], label=\"train\")\n",
    "ax.plot(history.history[\"val_loss\"], label=\"validation\")\n",
    "ax.set_title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos en total 6 salidas, una para cada paso de tiempo en la secuencia de entrada. Cada salida es una predicción de la temperatura para ese paso de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_to_many_preds = many_to_many.predict(test_data.values.reshape(-1, 6, 1))\n",
    "many_to_many_preds = many_to_many_preds.reshape(-1, 6)\n",
    "many_to_many_preds = pd.DataFrame(many_to_many_preds, columns=output_vars)\n",
    "many_to_many_preds.set_index(test_label.index, inplace=True)\n",
    "many_to_many_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a comparar los resultados obtenidos hora a hora con los datos reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(15, 5))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.plot(test_label.iloc[:, i], label=\"true\")\n",
    "    ax.plot(many_to_many_preds.iloc[:, i], label=f\"predicción {i+1}h\", ls=\"--\")\n",
    "    rmse = np.sqrt(\n",
    "        np.mean((test_label.iloc[:, i] - many_to_many_preds.iloc[:, i]) ** 2)\n",
    "    )\n",
    "    ax.set_title(f\"{output_vars[i]} RMSE: {rmse:.2f}\")\n",
    "    ax.legend()\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
