{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación práctica: Workshop de AI en Meteorología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/griverat/Meteo-AI/blob/main/notebooks/7.examen_practico.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si usa Google Colab, asegúrese de tener habilitada la GPU para este notebook.**\n",
    "\n",
    "![gpu_colab](https://github.com/griverat/Meteo-AI/blob/main/images/colab_gpu.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente notebook consta de una serie de ejercicios que deberán ser completados por los participantes del Workshop de AI en Meteorología. El objetivo de estos ejercicios es evaluar los conocimientos adquiridos durante el desarrollo del workshop.\n",
    "\n",
    "Para cada ejercicio se presentará una celda con un enunciado y, en la siguiente celda, un espacio para completar con el código necesario para resolver el ejercicio. Se pedirá que se complete el código faltante y que se ejecute la celda para verificar que el código funciona correctamente. Las secciones faltantes del código estarán marcadas con el comentario `# COMPLETAR` y estarán representadas por `__`.\n",
    "\n",
    "Al finalizar el notebook, se deberá descargar el notebook con los ejercicios resueltos y subirlo al formulario de Google correspondiente.\n",
    "\n",
    "¡Éxitos!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!wget https://github.com/griverat/Meteo-AI/raw/main/notebooks/data/temp_exam_data.nc -O data/temp_exam_data.nc\n",
    "!pip install cartopy cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cmocean as cmo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import xarray as xr\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"monospace\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio 1\n",
    "\n",
    "En este ejercicio se pide que se complete el código necesario para cargar un dataset de imágenes de satélite y se muestre una imagen de ejemplo.\n",
    "\n",
    "### Enunciado\n",
    "\n",
    "1. Cargar el dataset de temperatura desde la ruta `data/temp_exam_data.nc`.\n",
    "\n",
    "2. Mostrar una imagen de ejemplo del dataset. Para ello, hacer uso de la función `sel` de `xarray` y seleccionar un paso de tiempo cualquiera. i.e. `ds.sel(time='2020-01-01')`. Recordar que `xarray` permite usar `.plot()` para visualizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "temp = xr.open_dataarray(____)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "temp.sel(____).____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a intentar pronosticar los valores de temperatura para la siguiente semana usando los datos de temperatura de la ultima semana, para ello prepararemos los datos en los grupos correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input = temp.rolling(time=7).construct(\"channel\").isel(time=slice(6, None))\n",
    "temp_output = temp_input.copy(deep=True)\n",
    "\n",
    "# ya que rolling asigna el tiempo al ultimo valor de la secuencia, lo corregimos restando 6 dias\n",
    "# de esta manera el tiempo se asigna al valor inicial de la secuencia\n",
    "temp_output[\"time\"] = pd.to_datetime(temp_output.time) - pd.DateOffset(days=6)\n",
    "\n",
    "# finalmente, desplazamos la secuencia en un paso hacia adelante\n",
    "# de esta manera, el valor en el tiempo t, corresponde a los valores t+1, t+2, t+3, t+4, t+5, t+6\n",
    "temp_output = temp_output.shift(time=-1).isel(time=slice(0, -1))\n",
    "\n",
    "# seleccionamos los tiempos en comun\n",
    "min_time = max(temp_input.time.min(), temp_output.time.min())\n",
    "max_time = min(temp_input.time.max(), temp_output.time.max())\n",
    "\n",
    "temp_input = temp_input.sel(time=slice(min_time, max_time))\n",
    "temp_output = temp_output.sel(time=slice(min_time, max_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "En este ejercicio se pide que se complete el código para separar el dataset en conjuntos de entrenamiento y validación.\n",
    "\n",
    "### Enunciado\n",
    "\n",
    "1. Separar el dataset en conjuntos de entrenamiento (90%) y pruebas (10%). No definiremos el conjunto de datos de validación en este caso.\n",
    "\n",
    "2. Mostrar la cantidad de imágenes en cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "train_size = int(__ * __)\n",
    "test_size = len(temp) - train_size\n",
    "\n",
    "# Impriimir los tamaños de los conjuntos de entrenamiento y prueba\n",
    "print(___)\n",
    "print(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = temp_input.isel(time=slice(0, train_size))\n",
    "test_data = temp_input.isel(time=slice(train_size, None))\n",
    "\n",
    "train_label = temp_output.isel(time=slice(0, train_size))\n",
    "test_label = temp_output.isel(time=slice(train_size, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "En este ejercicio se pide que se complete el código para modificar la cantidad de datos de entrada y salida (chnannels) del dataset.\n",
    "\n",
    "### Enunciado\n",
    "\n",
    "1. Modificar la cantidad de canales de entrada y salida del dataset. En este caso, se pide que se utilicen 7 canales de entrada y 7 canales de salida.\n",
    "\n",
    "2. Inicializar un modelo de red neuronal convoluciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_block(x, n_filters):\n",
    "    x = tf.keras.layers.Conv2D(n_filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(n_filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = tf.keras.layers.MaxPool2D(2)(f)\n",
    "    p = tf.keras.layers.Dropout(0.3)(p)\n",
    "    return f, p\n",
    "\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "    x = tf.keras.layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.concatenate([x, conv_features])\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = double_conv_block(x, n_filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def unet_res():\n",
    "    # COMPLETAR\n",
    "    inputs = tf.keras.layers.Input(shape=(16, 16, ___))\n",
    "\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "\n",
    "    # COMPLETAR\n",
    "    outputs = tf.keras.layers.Conv2D(___, 1, padding=\"same\", activation=\"linear\")(u9)\n",
    "\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "    return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "unet_model = ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "En este ejercicio se pide que se complete el código para entrenar el modelo de red neuronal.\n",
    "\n",
    "### Enunciado\n",
    "\n",
    "1. Entrenar el modelo de red neuronal con los datos de entrenamiento. Escoger el optimizador de `adam` y la función de pérdida `mse`.\n",
    "\n",
    "2. Escoger los hiperparámetros para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "unet_model.compile(optimizer=___, loss=___)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=10, monitor=\"val_loss\", start_from_epoch=10\n",
    "    ),\n",
    "]\n",
    "\n",
    "# COMPLETAR\n",
    "history = unet_model.fit(\n",
    "    train_data.data,\n",
    "    train_label.data,\n",
    "    epochs=___,\n",
    "    batch_size=___,\n",
    "    validation_split=0.1,\n",
    "    callbacks=___,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "En este ejercicio se pide que se complete el código para evaluar el modelo de red neuronal.\n",
    "\n",
    "### Enunciado\n",
    "\n",
    "1. Graficar la curva de aprendizaje del modelo.\n",
    "\n",
    "2. Mostrar el error cuadrático medio obtenido. Recordar que las variables `test_data` y `test_label` contienen los datos de prueba y las etiquetas de prueba, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "metrics = pd.DataFrame(___.history)\n",
    "metrics.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "test_metrics = unet_model.evaluate(___, ___)\n",
    "print(f\"Test Loss: {test_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo\n",
    "\n",
    "Al haber completado los ejercicios anteriores, el siguiente bloque de código graficara el resultado del modelo junto al resultado esperado y el error.\n",
    "\n",
    "En esta sección no hay nada que completar, simplemente ejecutar el bloque de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = unet_model.predict(test_data)\n",
    "preds = xr.DataArray(\n",
    "    preds,\n",
    "    dims=[\"time\", \"lat\", \"lon\", \"channel\"],\n",
    "    coords={\n",
    "        \"time\": test_label.time,\n",
    "        \"lat\": test_label.lat,\n",
    "        \"lon\": test_label.lon,\n",
    "        \"channel\": temp_output.channel,\n",
    "    },\n",
    ")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indice aleatorio\n",
    "idx = np.random.randint(0, len(test_label))\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    7, 3, figsize=(12, 28), subplot_kw={\"projection\": ccrs.PlateCarree()}\n",
    ")\n",
    "\n",
    "# en la primera columna se muestran los valores esperados\n",
    "# en la segunda columna se muestran los valores predichos\n",
    "# en la tercera columna se muestran las diferencias entre los valores esperados y predichos\n",
    "\n",
    "plot_kwargs = dict(transform=ccrs.PlateCarree(), cmap=cmo.cm.thermal, vmin=-10, vmax=30)\n",
    "date = pd.to_datetime(temp_output.time[idx].values)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    for j, a in enumerate(ax):\n",
    "        if j == 0:\n",
    "            temp_output.isel(time=idx, channel=i).plot(ax=a, **plot_kwargs)\n",
    "            a.set_title(f\"True: {date+pd.DateOffset(days=i+1):%Y-%m-%d} (+{i+1} días)\")\n",
    "        elif j == 1:\n",
    "            preds.isel(time=idx, channel=i).plot(ax=a, **plot_kwargs)\n",
    "            a.set_title(f\"Pred: {date+pd.DateOffset(days=i+1):%Y-%m-%d} (+{i+1} días)\")\n",
    "        else:\n",
    "            (preds - temp_output).isel(time=idx, channel=i).plot(\n",
    "                ax=a, transform=ccrs.PlateCarree(), cmap=cmo.cm.balance, vmin=-5, vmax=5\n",
    "            )\n",
    "            a.set_title(f\"Diff: {date+pd.DateOffset(days=i+1):%Y-%m-%d} (+{i+1} días)\")\n",
    "\n",
    "        a.coastlines()\n",
    "\n",
    "fig.suptitle(f\"True vs Predicted - Inicialización: {date:%Y-%m-%d}\", y=1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opcional\n",
    "\n",
    "Ahora que logramos entrenar un modelo de red neuronal para el pronóstico de temperatura en los siguientes 7 días, ¿cómo podríamos mejorar el modelo? ¿el modelo tiene información suficiente para realizar un pronóstico preciso? ¿el modelo, en su estado actual, es capaz de diferenciar entre estaciones del año?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta\n",
    "(Hacer doble click para editar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meteo_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
